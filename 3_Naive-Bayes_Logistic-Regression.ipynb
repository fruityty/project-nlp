{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADA9_vz2L-pa"
      },
      "source": [
        "sentiment analysis dataset Fastfood_Opinion.csv ด้วยเทคนิค Naïve Bayes และ Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-yqfdSwC-yj",
        "outputId": "5d5a30db-7f26-42a0-e5dd-1441acfc45b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /opt/anaconda3/lib/python3.12/site-packages (5.0.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from pythainlp) (2.32.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.22.0->pythainlp) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.22.0->pythainlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.22.0->pythainlp) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.22.0->pythainlp) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "019Mxh_vWudq",
        "outputId": "b72acfa9-eb8d-494d-c1c2-7f1982562618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1K0VgdwYagNidu5k_y5pnSrGrGIOBPsyS' -O fastfood_opinion.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxCWaC0AGYI2"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3CKw6JNE3nB",
        "outputId": "895c6ebb-1b3c-4344-a55c-f21d9fdd2b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_bow  (642, 3542)\n",
            "(3542,)\n",
            "['M' 'MBK' 'Mall' 'Management' 'Market' 'McDonalds' 'Mega' 'Moouse'\n",
            " 'Mortor' 'Motorway' 'Mushroom' 'Nugget' 'Operation' 'Order' 'POS'\n",
            " 'Paradise' 'Park' 'Piroj' 'Pizza' 'Place']\n",
            "X_binary  (642, 3542)\n",
            "(3542,)\n",
            "['M' 'MBK' 'Mall' 'Management' 'Market' 'McDonalds' 'Mega' 'Moouse'\n",
            " 'Mortor' 'Motorway' 'Mushroom' 'Nugget' 'Operation' 'Order' 'POS'\n",
            " 'Paradise' 'Park' 'Piroj' 'Pizza' 'Place']\n",
            "X_bigram  (642, 3542)\n",
            "(3542,)\n",
            "['M' 'MBK' 'Mall' 'Management' 'Market' 'McDonalds' 'Mega' 'Moouse'\n",
            " 'Mortor' 'Motorway' 'Mushroom' 'Nugget' 'Operation' 'Order' 'POS'\n",
            " 'Paradise' 'Park' 'Piroj' 'Pizza' 'Place']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:541: UserWarning: The parameter 'ngram_range' will not be used since 'analyzer' is callable'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load and preprocess the data\n",
        "data = pd.read_csv('fastfood_opinion.csv')  # Replace 'your_dataset.csv' with the path to your dataset\n",
        "X = data['message'].astype(str)  # Text data in the 'message' column\n",
        "y = data['class']  # Labels in the 'class' column\n",
        "\n",
        "\n",
        "# Step 2: Create bag-of-words representation\n",
        "# Preprocess the data Before training the model, you need to preprocess the Thai text data to convert it into tokenized\n",
        "# and numerical features. We'll use scikit-learn's CountVectorizer to transform the text data into bag-of-word features (bow).\n",
        "\n",
        "# Tokenize Thai text\n",
        "X_tokenized = X.apply(word_tokenize, keep_whitespace=False)\n",
        "\n",
        "# Bag of Words\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)  # Use the list of tokens as the analyzer\n",
        "X_bow = vectorizer.fit_transform(X_tokenized)\n",
        "print(\"X_bow \", X_bow.shape) # (documents, vocab)\n",
        "\n",
        "vocab_bow = np.array(vectorizer.get_feature_names_out())\n",
        "print(vocab_bow.shape)\n",
        "print(vocab_bow[250:270])\n",
        "\n",
        "\n",
        "# Binary Term\n",
        "binary_vectorizer= CountVectorizer(analyzer=lambda x: x, binary=True)  # binary=True for binary term frequency\n",
        "X_binary = binary_vectorizer.fit_transform(X_tokenized)\n",
        "print(\"X_binary \", X_bow.shape) # (documents, vocab)\n",
        "\n",
        "vocab_binary = np.array(binary_vectorizer.get_feature_names_out())\n",
        "print(vocab_binary.shape)\n",
        "print(vocab_binary[250:270])\n",
        "\n",
        "# Bigram term\n",
        "bigram_vectorizer = CountVectorizer(analyzer=lambda x: x, ngram_range=(1, 2))\n",
        "X_bigram = bigram_vectorizer.fit_transform(X_tokenized)\n",
        "print(\"X_bigram \", X_bigram.shape) # (documents, vocab)\n",
        "\n",
        "vocab_bigram = np.array(bigram_vectorizer.get_feature_names_out())\n",
        "print(vocab_bigram.shape)\n",
        "print(vocab_bigram[250:270])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvU2KsBTKOrW",
        "outputId": "493cb6f8-28d4-4b75-df49-2cda0cf74947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Burger', 'King', 'สาขา', 'The', 'Bright', 'พระราม', '2', 'บริการ', 'ห่วย', 'มาก', 'ถึง', 'มาก', 'ที่สุด', 'วันนี้', 'ไป', 'ทาน', 'กับ', 'ลูก', '3', 'คน', 'พนักงาน', 'รับ', 'ออเดอร์', 'มัวแต่', 'คุย', 'เล่น', 'กัน', 'ยืน', 'กัน', 'หลาย', 'คน', 'แต่', 'เปิด', 'เคา', 'เตอร์', 'เดียว', 'กว่า', 'จะ', 'สั่ง', 'ได้', 'นาน', 'มาก', 'พอ', 'สั่ง', 'แล้ว', 'เฟรนฟ', 'ราย', 'หมด', 'พอดี', 'พนักงาน', 'บอ', 'กว่า', 'เดี๋ยว', 'เอา', 'ไป', 'ให้', 'ที่', 'โต๊ะ', 'ก็', 'ไม่เป็นไร', 'ก็', 'ไป', 'นั่ง', 'รอ', 'ก็', 'นั่ง', 'ป้อน', 'แฮมเบอร์เกอร์', 'ลูก', 'ๆ', 'ไป', 'ซัก', 'พักใหญ่', 'เฟรนฟ', 'ราย', 'ก็', 'ยัง', 'ไม่', 'มา', 'แต่', 'เห็น', 'โต๊ะ', 'อื่น', 'ที่มา', 'หลัง', 'เรา', 'ได้', 'แล้ว', 'ก็', 'ลุก', 'ไป', 'ตาม', 'กับ', 'ผู้จัดการ', '(', 'แต่งตัว', 'ไม่', 'เหมือน', 'คนอื่น', ')', 'ตาม', 'ครั้ง', 'ที่', '1', 'ก็', 'ได้รับ', 'คำตอบ', 'เหมือนเดิม', 'ไป', 'นั่ง', 'รอ', 'ที่', 'โต๊ะ', 'เดี๋ยว', 'ไป', 'เส', 'ริ', 'ฟ', 'ให้', 'จน', 'ป้อน', 'เด็ก', 'จน', 'หมด', 'ใช้เวลา', 'ประมาณ', '30', 'นาที', 'ก็', 'เดิน', 'ไป', 'ตาม', 'รอบ', 'ที่', '2', 'ทาง', 'ผู้จัดการ', 'ยื่น', 'มา', 'ให้', '1', 'ห่อ', 'ก่อน', '(', 'สั่ง', '2', 'ชุด', ')', 'บอ', 'กว่า', 'อีก', 'ห่อ', 'เดี๋ยว', 'ค่อย', 'เอา', 'ไป', 'เส', 'ริ', 'ฟ', 'ที่', 'โต๊ะ', '(', 'อีก', 'ละ', ')', 'จน', 'กลับมา', 'ที่', 'โต๊ะ', 'กิน', 'จน', 'หมด', 'อิ่ม', 'แล้ว', 'เฟรนฟ', 'ราย', 'อีก', 'ห่อ', 'ก็', 'ยัง', 'ไม่', 'มา', 'เส', 'ริ', 'ฟ', 'จน', 'ต้อง', 'ไป', 'ตาม', 'ครั้ง', 'ที่', '3', 'กับ', 'พนักงาน', 'เคา', 'เตอร์', 'พนักงาน', 'เข้าไป', 'คุย', 'กับ', 'ผู้จัดการ', 'เบา', 'ๆ', '(', 'แต่', 'แอบ', 'ได้ยิน', ')', '\"', 'พี่', 'ๆ', 'หนู', 'บอก', 'แล้ว', 'ว่า', 'จะ', 'ไป', 'เส', 'ริ', 'ฟ', 'พี่', 'บอ', 'กว่า', 'ไม่ต้อง', 'ลูกค้า', 'กลับ', 'ไป', 'แล้ว', 'เนี่ย', 'เขา', 'มา', 'ตาม', '\"', 'ได้ยิน', 'โมโห', 'มาก', 'เนี่ย', 'ถ้า', 'ไม่', 'ตาม', 'ก็', 'คง', 'ไม่', 'มา', 'เส', 'ริ', 'ฟ', 'ใช่', 'มั้ย', 'ขอ', 'บอ', 'กว่า', 'ใน', 'บรรดา', 'เบอร์เกอร์', 'ชอบ', 'กิน', 'Burger', 'King', 'มาก', 'ที่', 'สุดแต่', 'เจอ', 'พนักงาน', 'ยัน', 'ผู้จัดการ', 'แบบนี้', 'ขอ', 'บาย', 'ค่ะ']\n",
            "X_bow\n",
            "  (0, 3477)\t12\n",
            "  (0, 1341)\t8\n",
            "  (0, 2352)\t1\n",
            "  (0, 3418)\t1\n",
            "  (0, 2149)\t1\n",
            "  (0, 123)\t3\n",
            "  (0, 489)\t1\n",
            "  (0, 1237)\t1\n",
            "  (0, 857)\t2\n",
            "  (0, 1309)\t1\n",
            "  (0, 2906)\t1\n",
            "  (0, 1876)\t5\n",
            "  (0, 1524)\t1\n",
            "  (0, 682)\t2\n",
            "  (0, 576)\t9\n",
            "  (0, 3203)\t3\n",
            "  (0, 1877)\t5\n",
            "  (0, 701)\t2\n",
            "  (0, 846)\t5\n",
            "  (0, 3459)\t2\n",
            "  (0, 559)\t2\n",
            "  (0, 3487)\t5\n",
            "  (0, 3139)\t2\n",
            "  (0, 2242)\t1\n",
            "  (0, 679)\t1\n",
            "  :\t:\n",
            "  (0, 491)\t1\n",
            "  (0, 2631)\t1\n",
            "  (0, 1220)\t1\n",
            "  (0, 2721)\t1\n",
            "  (0, 2882)\t1\n",
            "  (0, 3309)\t1\n",
            "  (0, 3468)\t2\n",
            "  (0, 13)\t2\n",
            "  (0, 1783)\t2\n",
            "  (0, 2448)\t1\n",
            "  (0, 1532)\t1\n",
            "  (0, 3490)\t1\n",
            "  (0, 2177)\t1\n",
            "  (0, 2864)\t2\n",
            "  (0, 3375)\t1\n",
            "  (0, 3406)\t1\n",
            "  (0, 1873)\t1\n",
            "  (0, 1522)\t1\n",
            "  (0, 2879)\t1\n",
            "  (0, 918)\t1\n",
            "  (0, 2391)\t1\n",
            "  (0, 2751)\t1\n",
            "  (0, 1960)\t1\n",
            "  (0, 1556)\t1\n",
            "  (0, 818)\t1\n",
            "ไป\n",
            "ที่\n",
            "สาขา\n"
          ]
        }
      ],
      "source": [
        "# Bag of Words\n",
        "print(X_tokenized[2])\n",
        "print(\"X_bow\")\n",
        "print(X_bow[2])\n",
        "\n",
        "print(vocab_bow[3477])\n",
        "print(vocab_bow[1341])\n",
        "print(vocab_bow[2352])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1HXqiknxuCB",
        "outputId": "62151c23-4451-4603-8b10-7fdac2090fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_binary\n",
            "  (0, 3477)\t1\n",
            "  (0, 1341)\t1\n",
            "  (0, 2352)\t1\n",
            "  (0, 3418)\t1\n",
            "  (0, 2149)\t1\n",
            "  (0, 123)\t1\n",
            "  (0, 489)\t1\n",
            "  (0, 1237)\t1\n",
            "  (0, 857)\t1\n",
            "  (0, 1309)\t1\n",
            "  (0, 2906)\t1\n",
            "  (0, 1876)\t1\n",
            "  (0, 1524)\t1\n",
            "  (0, 682)\t1\n",
            "  (0, 576)\t1\n",
            "  (0, 3203)\t1\n",
            "  (0, 1877)\t1\n",
            "  (0, 701)\t1\n",
            "  (0, 846)\t1\n",
            "  (0, 3459)\t1\n",
            "  (0, 559)\t1\n",
            "  (0, 3487)\t1\n",
            "  (0, 3139)\t1\n",
            "  (0, 2242)\t1\n",
            "  (0, 679)\t1\n",
            "  :\t:\n",
            "  (0, 491)\t1\n",
            "  (0, 2631)\t1\n",
            "  (0, 1220)\t1\n",
            "  (0, 2721)\t1\n",
            "  (0, 2882)\t1\n",
            "  (0, 3309)\t1\n",
            "  (0, 3468)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 1783)\t1\n",
            "  (0, 2448)\t1\n",
            "  (0, 1532)\t1\n",
            "  (0, 3490)\t1\n",
            "  (0, 2177)\t1\n",
            "  (0, 2864)\t1\n",
            "  (0, 3375)\t1\n",
            "  (0, 3406)\t1\n",
            "  (0, 1873)\t1\n",
            "  (0, 1522)\t1\n",
            "  (0, 2879)\t1\n",
            "  (0, 918)\t1\n",
            "  (0, 2391)\t1\n",
            "  (0, 2751)\t1\n",
            "  (0, 1960)\t1\n",
            "  (0, 1556)\t1\n",
            "  (0, 818)\t1\n",
            "ไป\n",
            "ที่\n",
            "สาขา\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Binary Term\n",
        "print(\"X_binary\")\n",
        "print(X_binary[2])\n",
        "\n",
        "print(vocab_binary[3477])\n",
        "print(vocab_binary[1341])\n",
        "print(vocab_binary[2352])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKCoNOgPxurD",
        "outputId": "0ffac483-6dab-493b-89aa-5410dea822ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_bigram\n",
            "  (0, 3477)\t12\n",
            "  (0, 1341)\t8\n",
            "  (0, 2352)\t1\n",
            "  (0, 3418)\t1\n",
            "  (0, 2149)\t1\n",
            "  (0, 123)\t3\n",
            "  (0, 489)\t1\n",
            "  (0, 1237)\t1\n",
            "  (0, 857)\t2\n",
            "  (0, 1309)\t1\n",
            "  (0, 2906)\t1\n",
            "  (0, 1876)\t5\n",
            "  (0, 1524)\t1\n",
            "  (0, 682)\t2\n",
            "  (0, 576)\t9\n",
            "  (0, 3203)\t3\n",
            "  (0, 1877)\t5\n",
            "  (0, 701)\t2\n",
            "  (0, 846)\t5\n",
            "  (0, 3459)\t2\n",
            "  (0, 559)\t2\n",
            "  (0, 3487)\t5\n",
            "  (0, 3139)\t2\n",
            "  (0, 2242)\t1\n",
            "  (0, 679)\t1\n",
            "  :\t:\n",
            "  (0, 491)\t1\n",
            "  (0, 2631)\t1\n",
            "  (0, 1220)\t1\n",
            "  (0, 2721)\t1\n",
            "  (0, 2882)\t1\n",
            "  (0, 3309)\t1\n",
            "  (0, 3468)\t2\n",
            "  (0, 13)\t2\n",
            "  (0, 1783)\t2\n",
            "  (0, 2448)\t1\n",
            "  (0, 1532)\t1\n",
            "  (0, 3490)\t1\n",
            "  (0, 2177)\t1\n",
            "  (0, 2864)\t2\n",
            "  (0, 3375)\t1\n",
            "  (0, 3406)\t1\n",
            "  (0, 1873)\t1\n",
            "  (0, 1522)\t1\n",
            "  (0, 2879)\t1\n",
            "  (0, 918)\t1\n",
            "  (0, 2391)\t1\n",
            "  (0, 2751)\t1\n",
            "  (0, 1960)\t1\n",
            "  (0, 1556)\t1\n",
            "  (0, 818)\t1\n",
            "ไป\n",
            "ที่\n",
            "สาขา\n"
          ]
        }
      ],
      "source": [
        "# Bigram term\n",
        "print(\"X_bigram\")\n",
        "print(X_bigram[2])\n",
        "\n",
        "print(vocab_bigram[3477])\n",
        "print(vocab_bigram[1341])\n",
        "print(vocab_bigram[2352])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZyiESEvJ6Fn",
        "outputId": "e0c01654-c07f-4372-807b-f3f5153156e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bow\n",
            "Accuracy: 0.8837209302325582\n"
          ]
        }
      ],
      "source": [
        "# Bow\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the binomial logistic regression\n",
        "logreg_classifier = LogisticRegression()\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = logreg_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Bow\")\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHlHI2VazIq7",
        "outputId": "4fedeae5-e185-4853-ed1a-27de14621e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89        74\n",
            "           1       0.82      0.93      0.87        55\n",
            "\n",
            "    accuracy                           0.88       129\n",
            "   macro avg       0.88      0.89      0.88       129\n",
            "weighted avg       0.89      0.88      0.88       129\n",
            "\n",
            "Confusion Matrix:\n",
            "[[63 11]\n",
            " [ 4 51]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Print classification report (precision, recall, F1-score, support)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIyKEsRqysNm",
        "outputId": "93e29b10-3f92-461b-dc6d-f3966f10efbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Binary\n",
            "Accuracy: 0.9147286821705426\n"
          ]
        }
      ],
      "source": [
        "# Binary\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the binomial logistic regression\n",
        "logreg_classifier = LogisticRegression()\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = logreg_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Binary\")\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxqZupFKzKIn",
        "outputId": "2aa75727-f7b6-4cfd-99c4-4c77fdbc56f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.92        74\n",
            "           1       0.87      0.95      0.90        55\n",
            "\n",
            "    accuracy                           0.91       129\n",
            "   macro avg       0.91      0.92      0.91       129\n",
            "weighted avg       0.92      0.91      0.92       129\n",
            "\n",
            "Confusion Matrix:\n",
            "[[66  8]\n",
            " [ 3 52]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Print classification report (precision, recall, F1-score, support)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz_o7DIbyse0",
        "outputId": "b127a1f7-d229-4fdd-aedc-3b1cb3df33d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigram\n",
            "Accuracy: 0.8837209302325582\n"
          ]
        }
      ],
      "source": [
        "# Bigram\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bigram, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the binomial logistic regression\n",
        "logreg_classifier = LogisticRegression()\n",
        "logreg_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = logreg_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Bigram\")\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV0I0HVf8sUu",
        "outputId": "cd7dd5ce-5f9b-4839-f520-f830d927ba1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89        74\n",
            "           1       0.82      0.93      0.87        55\n",
            "\n",
            "    accuracy                           0.88       129\n",
            "   macro avg       0.88      0.89      0.88       129\n",
            "weighted avg       0.89      0.88      0.88       129\n",
            "\n",
            "Confusion Matrix:\n",
            "[[63 11]\n",
            " [ 4 51]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Print classification report (precision, recall, F1-score, support)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIzm3Uyu80sf",
        "outputId": "f15998fb-e80c-4c3e-f9a2-9445f2c38137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class:  1\n",
            "0    [กินที่, ร้าน, ดีกว่า, ครับ, ลอง, สั่ง, มา, กิ...\n",
            "dtype: object\n",
            "  (0, 562)\t2\n",
            "  (0, 698)\t1\n",
            "  (0, 705)\t1\n",
            "  (0, 722)\t1\n",
            "  (0, 739)\t1\n",
            "  (0, 1045)\t1\n",
            "  (0, 1046)\t1\n",
            "  (0, 1584)\t1\n",
            "  (0, 1876)\t1\n",
            "  (0, 1899)\t1\n",
            "  (0, 1951)\t1\n",
            "  (0, 2125)\t1\n",
            "  (0, 2144)\t1\n",
            "  (0, 2343)\t1\n",
            "  (0, 2585)\t1\n",
            "  (0, 3027)\t1\n",
            "  (0, 3107)\t1\n",
            "  (0, 3487)\t1\n"
          ]
        }
      ],
      "source": [
        "# Predict New Data: Example 1\n",
        "\n",
        "new_text = \"กินที่ร้านดีกว่าครับ ลองสั่งมากินที่บ้านครั้งแรก ไม่มีความร้อนเลย ความอร่อยยังดีเหมือนเดิม\"\n",
        "new_text = pd.Series(new_text)\n",
        "new_text_tokenized = new_text.apply(word_tokenize, keep_whitespace=False)\n",
        "new_text_bow = vectorizer.transform(new_text_tokenized)\n",
        "\n",
        "predicted_class = logreg_classifier.predict(new_text_bow)\n",
        "print(\"Predicted Class: \", predicted_class[0])\n",
        "\n",
        "print(new_text_tokenized)\n",
        "print(new_text_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1wpCC7d9VHc",
        "outputId": "b70e9f85-3d2e-4ca0-be81-300f691d8740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class:  0\n",
            "0    [พนักงาน, ช้า, มาก, ขนาด, เช้า, คน, ไม่, เยอะ,...\n",
            "dtype: object\n",
            "  (0, 576)\t1\n",
            "  (0, 597)\t1\n",
            "  (0, 682)\t1\n",
            "  (0, 976)\t1\n",
            "  (0, 1046)\t1\n",
            "  (0, 1464)\t1\n",
            "  (0, 1480)\t1\n",
            "  (0, 1723)\t2\n",
            "  (0, 1877)\t1\n",
            "  (0, 2149)\t1\n",
            "  (0, 2281)\t1\n",
            "  (0, 2289)\t1\n",
            "  (0, 2459)\t1\n",
            "  (0, 2781)\t1\n",
            "  (0, 2911)\t1\n",
            "  (0, 2989)\t1\n",
            "  (0, 3487)\t2\n"
          ]
        }
      ],
      "source": [
        "# Predict New Data: Example 2\n",
        "\n",
        "\n",
        "new_text = [\"พนักงานช้ามาก ขนาดเช้าคนไม่เยอะ ก็หน้าบึ้งละ ไม่สมเป็น fast food ระดับโลก น่าจะสนใจคัดเลือกพนักงานได่ดีกว่านี้\"]\n",
        "new_text = pd.Series(new_text)\n",
        "new_text_tokenized = new_text.apply(word_tokenize, keep_whitespace=False)\n",
        "new_text_bow = vectorizer.transform(new_text_tokenized)\n",
        "\n",
        "predicted_class = logreg_classifier.predict(new_text_bow)\n",
        "print(\"Predicted Class: \", predicted_class[0])\n",
        "\n",
        "print(new_text_tokenized)\n",
        "print(new_text_bow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYe8IIPJB_dw"
      },
      "source": [
        "# Naive Bays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFsl51sbB_pu",
        "outputId": "e01660c8-862a-479b-b7e3-91cb4bea2a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(642, 3542)\n",
            "Accuracy: 0.8992248062015504\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Step 1: Load and preprocess the data\n",
        "data = pd.read_csv('fastfood_opinion.csv')  # Replace 'your_dataset.csv' with the path to your dataset\n",
        "X = data['message'].astype(str)  # Text data in the 'message' column\n",
        "y = data['class']  # Labels in the 'class' column\n",
        "\n",
        "# Tokenize Thai text\n",
        "X_tokenized = X.apply(word_tokenize, keep_whitespace=False)\n",
        "\n",
        "# Step 2: Create bag-of-words representation\n",
        "vectorizer2 = CountVectorizer(analyzer=lambda x: x)  # Use the list of tokens as the analyzer\n",
        "X_bow = vectorizer2.fit_transform(X_tokenized)\n",
        "print(X_bow.shape) # (documents, vocab)\n",
        "\n",
        "# Step 3: Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the binomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7pTCZP7aYUP",
        "outputId": "fbfe75ef-4451-4569-f285-5b0c876f5b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: [0 0]\n",
            "0    [กินที่, ร้าน, ดีกว่า, ครับ, ลอง, สั่ง, มา, กิ...\n",
            "1    [พนักงาน, ช้า, มาก, ขนาด, เช้า, คน, ไม่, เยอะ,...\n",
            "dtype: object\n",
            "  (0, 562)\t2\n",
            "  (0, 698)\t1\n",
            "  (0, 705)\t1\n",
            "  (0, 722)\t1\n",
            "  (0, 739)\t1\n",
            "  (0, 1045)\t1\n",
            "  (0, 1046)\t1\n",
            "  (0, 1584)\t1\n",
            "  (0, 1876)\t1\n",
            "  (0, 1899)\t1\n",
            "  (0, 1951)\t1\n",
            "  (0, 2125)\t1\n",
            "  (0, 2144)\t1\n",
            "  (0, 2343)\t1\n",
            "  (0, 2585)\t1\n",
            "  (0, 3027)\t1\n",
            "  (0, 3107)\t1\n",
            "  (0, 3487)\t1\n",
            "  (1, 576)\t1\n",
            "  (1, 597)\t1\n",
            "  (1, 682)\t1\n",
            "  (1, 976)\t1\n",
            "  (1, 1046)\t1\n",
            "  (1, 1464)\t1\n",
            "  (1, 1480)\t1\n",
            "  (1, 1723)\t2\n",
            "  (1, 1877)\t1\n",
            "  (1, 2149)\t1\n",
            "  (1, 2281)\t1\n",
            "  (1, 2289)\t1\n",
            "  (1, 2459)\t1\n",
            "  (1, 2781)\t1\n",
            "  (1, 2911)\t1\n",
            "  (1, 2989)\t1\n",
            "  (1, 3487)\t2\n"
          ]
        }
      ],
      "source": [
        "new_text = [\"กินที่ร้านดีกว่าครับ ลองสั่งมากินที่บ้านครั้งแรก ไม่มีความร้อนเลย ความอร่อยยังดีเหมือนเดิม\", \"พนักงานช้ามาก ขนาดเช้าคนไม่เยอะ ก็หน้าบึ้งละ ไม่สมเป็น fast food ระดับโลก น่าจะสนใจคัดเลือกพนักงานได่ดีกว่านี้\"]\n",
        "new_text = pd.Series(new_text)\n",
        "new_text_tokenized = new_text.apply(word_tokenize, keep_whitespace=False)\n",
        "new_text_bow = vectorizer2.transform(new_text_tokenized)\n",
        "\n",
        "predicted_class = nb_classifier.predict(new_text_bow)\n",
        "print(\"Predicted Class:\", predicted_class)\n",
        "\n",
        "print(new_text_tokenized)\n",
        "print(new_text_bow)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
